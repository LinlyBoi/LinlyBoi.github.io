\documentclass[theme=sleek, randomorder, hidesidemenu]{webquiz}
\title{Tokenisation}
\begin{document}
\begin{question}

  Space-based tokenisation can be used for most languages like

  \begin{choice}[multiple, columns=2]
    \incorrect Japanese, Arabic, Greek and Chinese
    \correct Arabic
    \incorrect Thai
    \correct Cyrillic
  \end{choice}

\end{question}

\begin{question}

  Space-based tokenisation can be done with unix tools like:

  \begin{choice}[columns=2]
    \incorrect ed \feedback this is a text editor
    \correct tr
    \incorrect cp \feedback this copies...
    \incorrect cut \feedback this removes specific parts of a line based on position
  \end{choice}

\end{question}

\begin{question}

  We can remove punctuation since it holds no real meaning for machines

  \begin{choice}[columns=2]
    \incorrect True
    \correct False
  \end{choice}

\end{question}

\begin{question}

  Byte-Pair Encoding is composed of 2 parts which are

  \begin{choice}[columns=2]
    \incorrect learner and tokeniser
    \correct segmenter and learner
    \incorrect vocab corpus and tokens
    \incorrect segmenter and classifier
  \end{choice}

\end{question}

\begin{question}

  Byte-Pair Encoding often includes subwords like morphemes

  \begin{choice}[columns=2]
    \correct True
    \incorrect False
  \end{choice}

\end{question}

\begin{question}

  Morphological parsing is

  \begin{choice}[columns=2]
    \correct Dividing words into the smallest subwords with meaning
    \incorrect Finding which words have been morphed or modified
    \incorrect Identify changes that occurred to the root word
    \incorrect Parsing own words by morphing them into another entity or token
  \end{choice}

\end{question}

\begin{question}

  Stemming is a more sophisticated form of lemmatization

  \begin{choice}[columns]
    \incorrect True
    \correct False
  \end{choice}

\end{question}

\begin{question}

  Reducing relational to relate via a rule that turns ``ATIONAL'' TO ``ATE'' is an example of

  \begin{choice}[columns=2]
    \incorrect Stemming
    \correct Porter Stemmer
    \incorrect Lemmatisation
    \incorrect Regular Expressions
  \end{choice}

\end{question}

\begin{question}

  The most problematic symbol when segmenting sentences:

  \begin{choice}[columns=2]
    \incorrect ?
    \incorrect !
    \incorrect , \feedback that doesn't even separate sentences\ldots
    \correct .
  \end{choice}
\end{question}

\begin{question}

  What can we use to deal with symbols that may mark an end of sentence or part of a word?

  \begin{choice}
    \correct Use rules or machine learning to classify
    \incorrect Use word segmentation and prune symbols
    \incorrect Use POS (part of speech tagging)
    \incorrect Tokenise after filtering out symbols
  \end{choice}

\end{question}

\begin{question}

  What can we use to mitigate email scams?
  \begin{choice}[columns=2]
    \incorrect Text processing
    \correct Text classification
    \incorrect Sentiment analysis
    \incorrect Lemmatisation
  \end{choice}

\end{question}

\begin{question}

  Hybrid machine translation relies on
  \begin{choice}[columns=2]
    \correct Text classification
    \incorrect Text processing
    \incorrect Recurring Neural Networks
    \incorrect Data filtering
  \end{choice}

\end{question}

\begin{question}

  The first layer of Text classification is
  \begin{choice}[columns=2]
    \incorrect Classification Algorithm
    \correct Feature extract
    \incorrect Vector of features
    \incorrect Class label
    \incorrect Probability distribution
  \end{choice}

\end{question}

\end{document}
